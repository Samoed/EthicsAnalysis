#+STARTUP: latexpreview
#+TITLE: Site Development for automatic collection analysis and visualization of company ethical behavior
#+AUTHOR: Roman Solomatin
#+LANGUAGE: EN
#+LATEX_CLASS: ProjectProposal
#+LATEX_CLASS_OPTIONS: [PI]
#+bibliography: ../library.bib
#+cite_export: biblatex
#+OPTIONS: toc:nil H:4 ':t

Abstarct

* Introduction
The ethics of companies have long been of concern to stakeholders, particularly with regard to their actions in contentious situations and their delivery of customer-centric services. In recent years, there has been a growing emphasis on evaluating the ethical standards of companies, particularly in the banking sector and through the lens of Environmental, Social and Governance (ESG) factors[cite:@mure_esg_2021; @miralles-quiros_esg_2019; @climent_ethical_2018]. The need for such assessments has become increasingly urgent as society continues to grapple with the consequences of corporate misconduct and the broader impact of corporate activities on society as a whole.

Assessing a company's ethical standards is a complex process that involves evaluating various aspects of a company's operations, such as its business practices, policies, and overall culture. In addition to traditional financial metrics, ESG factors play a critical role in determining a company's overall ethical standing. All of this provides valuable insight into a company's ethical standards.

Currently, there are a number of services that claim to evaluate a company's ethics, but these evaluations are often based on court cases and other official records rather than customer feedback. This has resulted in a scenario where individuals must conduct their own research to determine the ethics of a particular company. This research often involves reviewing customer feedback from various websites, which can be time-consuming and may not always provide a comprehensive or accurate picture of a company's ethical practices.

To address this issue, there have been recent calls for the development of a system that would collect and analyze customer feedback from multiple websites to provide a more comprehensive view, and this system could also incorporate other data sources such as financial reports, sustainability reports, and news articles to provide a more holistic view of a company's ethical practices. The system could also incorporate machine learning algorithms, such as sentiment analysis and topic modeling, to analyze customer feedback and extract valuable insights. These insights could then be used to generate a score or rating that provides an overall assessment of a company's ethical practices.
* Literature Review
** Etics measurment
The importance of ethical behavior in business cannot be overstated. As evidenced by various studies and research [cite:@climent_ethical_2018; @mure_esg_2021], companies that prioritize ethical behavior tend to achieve greater financial success and better business performance over the long term than those that engage in unethical practices.

Evaluating a company's ethical standards can be approached from several perspectives. From the perspective of the company itself, various factors can be considered, including the level of capitalization to ensure that it is not at risk of bankruptcy, the impact it has on the surrounding environment, and the direction of its investments [cite:@harvey1995ethical]. On the other hand, customers may focus on the quality of customer service [cite:@brunk2010exploring] and the degree to which a company's services are intrusive [cite:@mitchell1992bank].

It is important to note that evaluating a company's ethics is not a one-time endeavor. Rather, it is an ongoing process that requires continuous monitoring and evaluation of the company's actions, policies and practices over time. This is particularly important given the constantly evolving nature of business conduct and the need to stay abreast of emerging issues and trends. In addition, it is important to consider the broader societal impacts of corporate activities and to evaluate companies not only on their financial performance, but also on their environmental, social and governance (ESG) factors.
** Text analyis
Machine learning algorithms for text analysis have been widely used to extract information from unstructured data using large annotated datasets. Among the various methods used, several algorithms have proven to be particularly effective in this area. These include the bag of words [cite:@doi:10.1080/00437956.1954.11659520], TF-IDF [cite:@jones1972statistical], Word2Vec [cite:@mikolov2013efficient], ELMO [cite:@elmo], GPT [cite:@radford2019language], and BERT [cite:@devlin2018bert]. Each of these algorithms has unique characteristics that make it well suited for specific applications.

The bag of words model represents text data by assigning a unique number to each word in a document. This method is easy to implement, but does not take into account the order of words in a sentence. On the other hand, the TF-IDF model represents text data by considering both the frequency of a word in a document (TF) and its rarity across all documents in the corpus (IDF). This approach can be used to determine the importance of a word in a given document and is commonly used in information retrieval and natural language processing tasks.

The field of natural language processing has seen a significant advancement in recent years, largely due to the emergence of neural network-based algorithms such as Word2Vec, ELMO, GPT, and BERT. These algorithms represent text data in a more nuanced and complex manner, allowing for a deeper understanding of the underlying semantics and meaning.

Word2Vec, for instance, utilizes a vector representation of words, which enables the algorithm to capture the meaning of words in similar contexts. This allows for a more accurate and sophisticated representation of the relationships between words, leading to improved performance in tasks such as text classification and sentiment analysis.

ELMO, GPT, and BERT, on the other hand, are based on the transformer architecture, in which each sentence is represented by a vector of numbers, commonly known as an embedding. This representation allows for a more comprehensive and holistic understanding of the text, as it takes into account the context of the entire sentence or text.

Of these algorithms, BERT is considered to be the most advanced and powerful, as it is able to consider the context of the entire sentence or text, whereas GPT and ELMO only consider a one-sided context. This allows BERT to achieve state-of-the-art performance in a wide range of NLP tasks, including text classification, named entity recognition, and question answering.

* Results Anticipated
* Conclusion
#+latex: %\nocite{*}
#+LATEX: \putbibliography
#+LATEX: \appendix
