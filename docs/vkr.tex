% Created 2023-04-30 Вс 02:38
% Intended LaTeX compiler: pdflatex
\documentclass[PI, VKR]{HSEUniversity}
                \Year{\the\year{}}
                                \supervisor{к.т.н.}{доцент кафедры информационных технологий в бизнесе НИУ ВШЭ-Пермь}{А. В. Бузмаков}
\Abstract{В данной работе проведен анализ этичности разных компаний.

В первой главе находится описание используемых алгоримов.

Во второй главе представлено проектирование системы.

В третьей главе представлена реализация системы.

В четвертой главе представлено тестирование работы системы.

Количество страниц -- \pageref*{pg:end}, количество иллюстраций -- \TotalValue{totalfigures}, количетсво таблиц -- \TotalValue{totaltables}.
}
\author{Соломатин Роман Игоревич}
\date{\today}
\title{Разработка системы для автоматического сбора, анализа и визуализации информации по этичности компаний}
\hypersetup{
 pdfauthor={Соломатин Роман Игоревич},
 pdftitle={Разработка системы для автоматического сбора, анализа и визуализации информации по этичности компаний},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.6.1)},
 pdflang={Russian}}
\usepackage{biblatex}
\addbibresource{~/Desktop/notes/org/bibliography.bib}
\begin{document}

\maketitle

\chapter*{Введение}
\label{sec:orgf616ea9}
Этика компаний – это разделяемые всеми сотрудниками организации правила и нормы, ценности и убеждения, манера общения и другие факторы, которые регламентируют поведение и взаимодействии членов компании. Существует 3 уровня этики компаний\autocite{smirnova_biznesetika_2021}:
\begin{enumerate}
\item мировой -- отвечает за увеличение общественного благосостояния, обеспечение рабочих мест, научно-технические инновации и модернизацию производственных процессов и т. д.
\item макроуровень -- отвечает за принципы рыночной конкуренции, информационной прозрачность и равнодоступности для всех участников рынка и т. д.
\item микроуровне -- отвечает за доверие и отсутствие дискриминации в отношениях между контрагентами, между сотрудниками и менеджерами, морально-нравственный климат в организации и т. д.
\end{enumerate}

В данной работе будет рассматриваться этика на микроуровне, как принятие каких-то действий, которые краткосрочно не обязательно выигрышных для бизнеса, но которые увеличивают лояльность людей. Например, у клиента банка задержали зарплату и он не делает платеж по кредиту. Формально банк может по кредитному договору снять штраф, но войдя в ситуацию учитывая, что опоздание маленькое, он этого не делает.

Этичность компаний уже давно вызывает озабоченность, особенно их поведение в спорных ситуациях и предоставление услуг, ориентированных на клиента. В последние годы все большее внимание уделяется оценке этичности компаний\autocites{mure_esg_2021}[][]{semenko_korporativnaya_2022}[][]{kudryavceva_korporativnosocialnaya_2016}, особенно в банковском секторе и через призму экологических, социальных и управленческих факторов (ESG). Необходимость в таких оценках становится все более острой по мере того, как общество продолжает бороться с последствиями неправомерных действий корпораций и более широким воздействием корпоративной деятельности на общество и окружающую среду.

В настоящее время существует несколько сервисов, которые призваны оценивать этику компании на основании финансовых показателей\footnote{\url{https://kontur.ru/expert}, \url{https://www.esphere.ru/products/spk/financial}} и судебных дел\footnote{\url{https://proverki.gov.ru/portal/public-search}}. Это привело к ситуации, когда отдельные лица должны проводить свои собственные исследования, чтобы определить насколько этична компания. Это часто включает в себя просмотр отзывов с различных веб-сайтов, что может занять много времени и не всегда может дать исчерпывающую или точную картину, так как не включает в себя качество обслуживания.

Для решения этой проблемы реализована система, которая собирает и анализирует отзывы потребителей с различных веб-сайтов, чтобы дать более полную и точную оценку этической практики компании. Затем собранные данные анализируются с помощью различных методов, таких как обработка естественного языка и машинного обучения, для выявления закономерностей и тенденций, связанных с этической практикой компании. Полученный анализ может быть использован для разработки более надежной и достоверной системы оценки этичности компаний.

Объект исследования – взаимодействие компаний с клиентами.

Предмет исследования – программные средства для оценки этичности на основе взаимодействия компаний с клиентами.

Цель работы – создание системы для оценки этичности компаний.

Исходя из поставленной цели, необходимо:

\begin{enumerate}
\item Провести анализ предметной области и требований
\item Реализовать систему
\item Провести тестирование системы
\end{enumerate}

Этап анализа должен:
\begin{enumerate}
\item Анализ предметной области
\item Анализ требований к системе
\item Анализ существующих алгоритмов
\end{enumerate}

Этап проектирования должен включать:
\begin{enumerate}
\item Проектирование серверной части
\item Проектирование модели для определения этичности
\item Проектирование клиентской части приложения
\end{enumerate}

Этап реализации должен включать:
\begin{enumerate}
\item Описание сбора данных
\item Реализации модели
\item Реализации серверной части
\item Реализации клиентской части
\end{enumerate}

Этап тестирования должен включать:
\begin{enumerate}
\item Тестирование модели
\item Тестирование серверной части
\item Тестирование клиентской части
\end{enumerate}

В ходе выполнения анализа, проектирования и реализации приложения используется объектно-ориентированный подход. Результаты анализа и решения задач проектирования формализуются с помощью диаграмм \texttt{UML}. При разработке базы данных используется реляционная СУБД \texttt{PostgreSQL}, а серверная часть приложения реализуется на языке python с помощью фреймворка \texttt{FastApi}, а алгоритмы анализы текста будут использовать методы машинного обучения.
\chapter{Анализ предметной области}
\label{sec:org7c6f612}
В данной главе представлен аналитический обзор оценок этичности компаний и алгоритмов машинного обучения, а также обзор существующих программных решений для поставленной проблемы.

Анализ предметной области следует разделить на следующие пункты:
\begin{enumerate}
\item анализ процесса определения этичности компаний сейчас позволяет понять, как этот процесс сейчас происходит и как его лучше всего автоматизировать;
\item анализ оценок этичности компаний для того, чтобы в дальнейшем определить этичность компаний;
\item анализ существующих решений выполняется с целью выделения их сильных и слабых сторон по отношению к решаемой проблеме и обоснования необходимости разработки нового средства, подходящего под регламент задач;
\item анализ алгоритмов позволяет понять с помощью каких алгоритмов можно найти полезную информацию в текстах;
\item анализ требований к системе позволит выделить функциональные и не функциональные требования.
\end{enumerate}
\section{Анализ определения этичности компании}
\label{sec:org24d2c3d}
Сейчас процесс поиска этичной компании выгладит следующим образом: сначала ищутся компании, которые предоставляют желаемые услуги. Далее они изучаются, чтобы определить их этичность. Этот процесс включает в себя:
\begin{enumerate}
\item просмотр отчетности компании
\item анализ ее финансовой деятельности
\item изучение информации о социальной ответственности
\end{enumerate}

Для этого они обращаются к различным источникам информации, таким как веб-сайты компаний, рейтинговые агентства, исследовательские организации и другие источники. Потом, изучаются социальные сети компании или отзывы пользователей на разных сайтах, форумах и социальных сетях, чтобы получить дополнительную информацию и оценить общее мнение о компании. После изучения каждой компании люди выбирают ту, которую они считают наиболее этичной и социально ответственной. Блок-схема данного поиска рис. \ref{fig:as_is}. Важным фактором для определения этичности компании может быть ее социальная ответственность, устойчивость бизнеса и соблюдение норм и стандартов в области финансовой деятельности.

В целом, процесс поиска компаний и определения их этичности может быть длительным и требует серьезного подхода. Люди могут использовать различные источники информации, чтобы сделать осознанный выбор и инвестировать свои деньги в компанию, которая соответствует их ожиданиям и требованиям.
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{img/mermaid/as_is.png}
\caption{\label{fig:as_is}Диаграмма того, как сейчас происходит поиск компании}
\end{figure}

\section{Анализ оценок этичности компаний}
\label{sec:orgbeca908}
Оценка этики компании -- это не одноразовый процесс, а скорее непрерывная попытка понять и оценить действия, политику и практику компании с течением времени. Это включает в себя рассмотрение соблюдения компанией отраслевых этических стандартов и передовой практики, а также мониторинг любых изменений в этической позиции компании с течением времени. Кроме того, участие в диалоге с компанией и консультации с организациями, специализирующимися на оценке корпоративной ответственности могут дать ценную информацию об этических практиках компании.

Компаниям важно оставаться этичными, так как на долгосрочной перспективе это приносит большую прибыль и улучшает показатели бизнеса, чем неэтичный способ ведение бизнеса\autocites{climent_ethical_2018}[][]{mure_esg_2021}. Насколько этична компания можно рассматривать с двух сторон, самой компании и их клиентов. Со стороны компаний можно выделить факторы, которые можно получить из их отчетности:
\begin{itemize}
\item количество капитала, чтобы они не могли обанкротиться;
\item какое влияние они вносят на окружающую среду;
\item куда идут инвестиции\autocite{harvey_ethical_1995}.
\end{itemize}
Для пользователей одними из ключевых факторов можно выделить:
\begin{itemize}
\item качество пользовательского сервиса\autocite{brunk_exploring_2010}, как правило пользователи оставляют отзывы на сайтах по 5-ти бальной шкале;
\item насколько навязчивые услуги компании\autocite{mitchell_bank_1992}, как правило пользователи оставляют отзывы на сайтах по 5-ти бальной шкале.
\end{itemize}

В данной работе этичность компаний будет определяться по отзывам клиентов, которые освещают проблемы качества услуг и качество сервиса, и на основе отчетности компаний, что позволит полностью осветить проблему. Для анализа текстов будут использоваться алгоритмы машинного обучения.
\section{Анализ существующих решений}
\label{sec:org2f42011}
Существует несколько индексов, предназначенных для измерения этичности -- индекс Доу Джонса (DJSI)\autocite{lopez_sustainable_2007} и FTSE4GOOD\autocite{collison_financial_2008}.

DJSI оценивает показатели устойчивости компаний различных секторов на основе экономических, экологических и социальных критериев. Компании отбираются на основе их показателей по сравнению с аналогичными компаниями в том же секторе. Процесс оценки включает в себя тщательную оценку компаний по различным критериям, включая корпоративное управление, экологический менеджмент, трудовую практику, права человека и социальные вопросы.

Аналогичным образом, индекс FTSE4GOOD предназначен для оценки деятельности компаний, которые демонстрируют эффективную практику экологического, социального и управленческого менеджмента (ESG). Компании отбираются на основе их практики ESG и оцениваются по различным критериям, включая изменение климата, права человека и корпоративное управление.

Индексы DJSI и FTSE4GOOD разработаны для того, чтобы помочь инвесторам определить компании, которые привержены этической практике. Эти индексы предоставляют инвесторам стандартизированный способ сравнения компаний на основе их показателей. Это помогает инвесторам принимать более обоснованные инвестиционные решения и побуждает компании внедрять устойчивую практику для привлечения инвестиций.

Для российских компаний нет аналогичных индексов. Сейчас данные об этичности компаний можно получить из агрегаторов отзывов и отчётности. Агрегаторы позволяют собрать информацию о клиентском обслуживании, а отчетность компаний о положении дел в целом. Но сейчас не существует способов, как можно оценить все вместе.
\section{Алгоритмы для анализа текста}
\label{sec:org002718a}
Алгоритмы машинного обучения для анализа текста получили широкое распространение для извлечения информации из неструктурированных данных с помощью больших помеченных наборов данных. Среди различных используемых методов несколько алгоритмов оказались особенно эффективными в этой области. К ним относятся мешок слов\autocite{harris_distributional_1954}, TF-IDF\autocite{jones_karen_sparck_statistical_1972}, Word2Vec\autocite{mikolov_distributed_2013}, ELMO\autocite{peters_deep_2018}, GPT\autocite{radford_language_2019} и BERT\autocite{devlin_bert_2019}. Каждый из этих алгоритмов обладает уникальными характеристиками, которые делают их хорошо подходящими для определенных приложений.

Модель {}<<Мешок слов>>{} представляет текстовые данные путем присвоения уникального номера каждому слову в документе. Этот метод прост в реализации, но не учитывает порядок слов в предложении. С другой стороны, модель TF-IDF представляет текстовые данные, учитывая как частоту слова в документе (TF), так и его редкость во всех документах корпуса (IDF). Этот подход может быть использован для определения важности слова в данном документе и обычно используется в задачах поиска информации и обработки естественного языка, но он не понимает контекста слов.

Word2Vec использует векторное представление слов, что позволяет алгоритму улавливать значение слов в сходных контекстах. Это позволяет более точно и изощренно представлять взаимосвязи между словами, что приводит к повышению производительности в таких задачах, как классификация текста и анализ настроений.

ELMO, GPT и BERT, с другой стороны, основаны на архитектуре трансформеров, в которой каждое предложение представлено вектором чисел, обычно известным как вложение. Такое представление позволяет получить более полное и целостное понимание текста, поскольку оно учитывает контекст всего предложения или текста.

Из этих алгоритмов BERT считается наиболее продвинутым и мощным, поскольку он способен учитывать контекст всего предложения или текста, в то время как GPT и ELMO рассматривают только односторонний контекст. Это позволяет BERT достигать самых современных результатов в широком спектре задач анализа естественного языка.

Таблица результата сравнения моделей \ref{tbl:model_compare}.
\begin{table}[h!]
\caption{\label{tbl:model_compare}Сравнение моделей}
\centering
\begin{tabular}{|c|c|c|}
\hline
Модель & Вектор слов & Контекст\\[0pt]
\hline
Мешок слов & зависит от количества слов & нет\\[0pt]
\hline
TF-IDF & зависит от количества слов & очень слабо\\[0pt]
\hline
Word2Vec & не зависит от количества слов & слабо\\[0pt]
\hline
ELMO & не зависит от количества слов & однонаправленный\\[0pt]
\hline
GPT & не зависит от количества слов & однонаправленный\\[0pt]
\hline
BERT & не зависит от количества слов & двунаправленный\\[0pt]
\hline
\end{tabular}
\end{table}

\subsection{BERT}
\label{sec:org9da64e1}
BERT \autocite{devlin_bert_2019} (Bidirectional Encoder Representations from Transformers) -- это нейросетевая языковая модель, которая относится к классу трансформеров. Она состоит из 12 «базовых блоков» (слоев), а на каждом слое 768 параметров.

На вход модели подается предложение или пара предложений. Затем разделяется на отдельные слова (токены). Потом в начало последовательности токенов вставляется специальный токен \texttt{[CLS]}, обозначающий начало предложения или начало последовательности предложений. Пары предложений группируются в одну последовательность и разделяются с помощью специального токена \texttt{[SEP]}, затем к каждому токену добавляется эмбеддинг, показывающий к какому предложению относится токен. Потом все токены превращаются в эмбеддинги \ref{fig:inputemebeddings} по механизму описаному в работе \autocite{vaswani_attention_2017}.

\begin{figure}[h]
\centering
\includegraphics[width=.9\linewidth]{img/Input_Emebeddings.pdf}
\caption{\label{fig:inputemebeddings}Пример ввода текста в модель}
\end{figure}

При обучении модель выполняет на 2 задания:
\begin{enumerate}
\item Предсказание слова в предложении

Поскольку стандартные языковые модели либо смотрят текст слева направо или справа налево \ref{fig:BERT_comparisons}, как ELMo\autocite{peters_deep_2018} и GPT\autocite{radford_language_2019}, они не подходят под некоторые типы заданий. Так как BERT двунаправленный, у каждого слова можно посмотреть его контекст, что позволит предсказать замаскированное слово.

\begin{figure}[h]
\centering
\includegraphics[width=.9\linewidth]{img/BERT_comparisons.pdf}
\caption{\label{fig:BERT_comparisons}Сравнение принципов работы BERT, ELMo, GPT}
\end{figure}

Это задание обучается следующим образом -- 15\% случайных слов заменяются в каждом предложении на специальный токен \texttt{[MASK]}, а затем предсказываются на основании контекста. Однако иногда слова заменяются не на специальны токена, в 10\% заменяются на случайный токен и еще в 10\% заменяются на случайное слово.

\item Предсказание следующего предложения

Для того чтобы обучить модель, которая понимает отношения предложений, она предсказывает, идут ли предложения друг за другом. Для этого с 50\% вероятностью выбирают предложения, которые находятся рядом и наоборот. Пример ввода пары предложений в модель \ref{fig:bert_pretrainin}.

\begin{figure}[hbp]
\centering
\includegraphics[width=0.6\textwidth]{img/bert_pretrainin.png}
\caption{\label{fig:bert_pretrainin}Схемам работы BERT}
\end{figure}
\end{enumerate}
\subsection{Sentence BERT}
\label{sec:orgc60b289}
Sentense BERT \autocite{reimers_sentence-bert_2019} -- это модификация предобученных моделей BERT, которая использует 2 модели BERT, затем усреднят их выходы, а после с помощью функции ошибки выдаёт результат. Схема работы модели \ref{fig:sbert}.
\begin{figure}[h!]
\centering
\includegraphics[width=0.6\textwidth]{img/sbert.png}
\caption{\label{fig:sbert}Схема работы SBERT}
\end{figure}
Основное преимущество данной модели над классическим BERT: эмбеддинги предложений можно сравнивать друг с другом независимо и не пересчитывать их пару каждый раз. Например, если для поиска похожих предложений из 10000 для обычного BERT потребуется 50 миллионов вычислений различных пар предложений, и это займёт 50 часов, то Sentense BERT рассчитает эмбеддинг каждого предложения отдельно, потом их сравнит. Такой способ рассчета ускоряет работу программы до 5 секунд.
\section{Анализ требований к системе}
\label{sec:org986e136}
Исходя из интервью с пользователями система должна уметь:
\begin{enumerate}
\item Показывать историю изменений индекса с возможностью фильтровать по:
\begin{enumerate}
\item годам;
\item отраслям компаний, с возможностью множественного выбора;
\item компаниям, с возможностью множественного выбора;
\item моделям, с возможностью множественного выбора;
\item источникам, с возможностью множественного выбора.
\end{enumerate}
\item Агрегировать значения индекса по годам и кварталам;
\item Анализировать тексты для построения индекса этичности;
\item Иметь возможность добавления анализа текста несколькими вариантами;
\item Сохранять тексты для последующего анализа другими методами;
\item Система должна собирать данные с сайтов banki.ru, sravni.ru и комментарии из групп {}<<вконтаке>>{};
\item На сайте должен быть график, который показывать изменение индекса этичности компаний и количества собранных отзывов по разным источникам.
\item Для расчета индекса этичности компаний на основании рецензий должна использоваться формула\ref{eq:ethics}:
\end{enumerate}

\begin{equation}
\label{eq:ethics}
\begin{aligned}
\text{Base index} &= \frac{\text{positive} - \text{negative}}{\text{positive} + \text{negative}} \\
\text{Std index} &= \sqrt{\frac{\text{positive}}{\text{negative} \cdot (\text{positive} + \text{negative})^{3}} + \frac{\text{negative}}{\text{positive} \cdot (\text{positive} + \text{negative})^{3}}} \\
\text{Index} &= ({2\cdot({\text{Base index}}-{\text{Mean index}} > 0) - 1})\cdot\\
            &{max\left(\left|{\text{Base index}}-{\text{Mean index}}\right|-{\text{Std index}}, 0\right)}
\end{aligned}
\end{equation}

\(positive\) -- количество позитивных предложений,

\(negative\) -- количество негативных предложений,

\(Mean\ index\) -- среднее значения для пар источник сбора данных и модели, которая обрабатывала предложения.

На основе описания функциональных требований была создана диаграмма вариантов использования, которая представлена на рисунке \ref{fig:usecasefull}.
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{img/use-case.png}
\caption{\label{fig:usecasefull}Диаграмма вариантов использования}
\end{figure}

Также были получены нефункциональные требования:
\begin{enumerate}
\item построение графика не должно занимать больше секунды;
\item данные должны собираться автоматически;
\item данные должны обрабатываться автоматически;
\item система должны способна работать с большим объемом информации;
\item система должна быть стабильна.
\end{enumerate}
\section{Выбор технологий для разработки}
\label{sec:org0f5c56c}
Для реализации этой системы будет использоваться язык Python. Для этого языка разработано много библиотек, которые позволят быстро реализовать нейротропные алгоритмы обработки естественного языка, в частности в этом проекте будет использоваться Pytorch\autocite{paszke_pytorch_2019} и HuggingFace\autocite{wolf_transformers_2020}, и собирать данные с сайтов. Для реализации API будет использоваться FastAPI, что позволит разрабатывать API с автоматической документацией.

Хранение данных будет использоваться объектно-реляционная система управления базами данных PostgreSQL, что позволит обрабатывать большие объемы данных. Для работы с ней будет использоваться Code first подход, с помощью Python библиотек Sqlalchemy и Alembic для изменения схемы данных (миграций).
\section{Выводы по главе}
\label{sec:org6550a6f}
По итогам анализа предметной области, можно сделать вывод о том, что определение этичности компаний является важной задачей, которую можно автоматизировать с помощью алгоритмов машинного обучения. Анализ оценок этичности компаний позволяет понять, какие факторы необходимо учитывать при разработке алгоритмов. Обзор существующих решений показал, что некоторые из них имеют свои преимущества и недостатки, и может потребоваться разработка нового средства, учитывающего особенности задачи. Анализ алгоритмов помогает выбрать наиболее подходящие алгоритмы для поиска полезной информации в текстах. Наконец, анализ требований к системе позволяет определить необходимые функциональные и нефункциональные требования, которые будут учитываться при разработке решения. В целом, эти аналитические пункты помогут определить оптимальный подход к решению задачи определения этичности компаний.
\chapter{Проектирование системы}
\label{sec:orgf3ab48d}
В данной главе определена общая архитектура системы и каждого микросервиса, осуществлено проектирование баз данных, API микросервисов для модуля анализа для универсальной рекомендательной системы.
\section{Проектирование архитектуры системы}
\label{sec:org6ca60b9}
Система будет разделена на отдельные независимые компоненты (микросервисы), что позволит ей быть надежной, если в какой-то части системы будут сбои, то остальная часть системы продолжит работать, и масштабируемой, легко добавлять новые компоненты. Каждый микросервис системы будет представлять собой docker container, которые будут управляться с помощью docker compose. Каждый сервис будет реализовывать отдельный компонент бизнес-логики и коммуницировать с другими компонентами через HTTP API.

Было выделено 4 главных компонента бизнес логики:
\begin{enumerate}
\item Работа с базой данных -- это HTTP API, который обеспечивает возможность сохранения и получения данных из базы данных. Данный компонент принимает запросы на сохранение данных, получение информации из базы данных и возвращает результаты обработки этих запросов.
\item Сбор данных -- компонент, который отвечает за сбор информации с нескольких источников. Для этого используется несколько независимых сборщиков данных, которые работают с различными сайтами и другими источниками.
\item Обработка данных -- данный компонент содержит несколько моделей, которые используются для анализа данных. Эти модели производят различные виды анализа, от простой фильтрации и сортировки до более сложных операций анализа и прогнозирования.
\item Агрегирование данных -- этот компонент отвечает за агрегацию обработанных данных в единый индекс. Данный индекс может быть использован для удобного представления полученных результатов в виде отчетов и графиков.
\end{enumerate}

Результат архитектуры системы на рис. \ref{fig:architecture}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/architecture.png}
\caption{\label{fig:architecture}Диаграмма архитектуры системы}
\end{figure}

Сервис для работы с базой данных, который будет обеспечивать сохранение и получение информации из различных сервисов сбора и обработки данных. Для этого будет предоставлен API, который будет использоваться для отправки и получения данных.

Сервисы сбора данных будут отправлять собранные тексты в формате JSON на сервис работы с базой данных с помощью HTTP запросов. Кроме того, информация, необходимая для сбора данных, будет храниться в базах данных соответствующих сервисов.

Сервис агрегации данных будет периодически обновлять базу данных один раз в день для обеспечения актуальности данных.

Сервис сбора данных будет включать несколько моделей машинного обучения, которые будут использоваться для анализа данных, полученных из сервиса сбора данных. После обработки данных, результаты будут отправляться обратно в сервис сбора данных.
\section{Проектирование базы данных}
\label{sec:org251fe67}
Исходя из поставленных требований было решено разделить базу данных на 2 подчасти:
\begin{enumerate}
\item Основная база данных будет хранить данные;
\item База данных для агрегации будет позволять быстро получать агрегированные данные.
\end{enumerate}

\subsection{Проектирование основной базы данных}
\label{sec:orga706032}
На основании требований была разработана следующая схема базы данных:

Таблица сфер компаний позволяет в дальнейшей удобно фильтровать данные в зависимости от типа компании.

\begin{center}
\begin{longtblr}[caption={Таблица сфера компании\label{tbl:company_type}}]{colspec={|X[2,l]|X[1,l]|X[3,l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Сфера компании & Строка & \\[0pt]
\end{longtblr}
\end{center}

\begin{center}
\begin{longtblr}[caption={Таблица компаний\label{tbl:companies}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Название компании & Строка & \\[0pt]
Описание компании & Строка & Дополнительное поле для сохранения вспомогательной информации о компании\\[0pt]
Лицензия компании & Строка & По лицензии компаний может будет сопоставлять компании на разных сайтах\\[0pt]
Код сферы компании & Целое & Внешний ключ из таблицы Сфера компании\\[0pt]
\end{longtblr}
\end{center}

Аналогично для сфер компаний таблица для типов источников позволяет удобно работать с данными в дальнейшем.

\begin{center}
\begin{longtblr}[caption={Таблица тип источников\label{tbl:source_type}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Название типа источника & Строка & \\[0pt]
\end{longtblr}
\end{center}

Таблица источников будет хранить информацию об источниках и когда было последнее обновление данных для них (в полях {}<<состояние сборщика данных>>{} и {}<<дата последнего сбора данных>>{}). Поле {}<<состояние сборщика данных>>{} будет иметь формат json, так как для разных источников информации потребуется сохранять информацию в различном виде и сложно определить наиболее подходящий формат заранее.

\begin{center}
\begin{longtblr}[caption={Таблица источники\label{tbl:sources}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Сайт & Строка & Сайт источника\\[0pt]
Код типа источника & Целое & Внешний ключ из таблицы тип источника\\[0pt]
Состояние сборщика данных & JSON & Данные о текущем состояние сборщика данных, если возникнет сбой\\[0pt]
Дата последнего сбора & DateTime & Точка когда сбор данных закончился, для дальнейшего сбора данных\\[0pt]
\end{longtblr}
\end{center}

Аналогично для сфер компаний таблица для типов модели позволяет удобно работать с данными в дальнейшем.

\begin{center}
\begin{longtblr}[caption={Таблица тип модели\label{tbl:model_type}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Название модели & Строка & \\[0pt]
\end{longtblr}
\end{center}

\begin{center}
\begin{longtblr}[caption={Таблица модели\label{tbl:model}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Название модели & Строка & \\[0pt]
Код типа модели & Целое & Внешний ключ на таблицу тип модели\\[0pt]
\end{longtblr}
\end{center}

\begin{center}
\begin{longtblr}[caption={Таблицы текст\label{tbl:text}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Ссылка & Строка & Ссылка на текст\\[0pt]
Код источника & Целое & Внешний ключ из таблицы источники\\[0pt]
Дата текста & DateTime & Время публикации текста\\[0pt]
Заголовок & Строка & Заголовок текста\\[0pt]
Код компании & Целое & Внешний ключ на компанию\\[0pt]
Количество комментариев & Целое & \\[0pt]
\end{longtblr}
\end{center}

Так как Bert на вход принимает отдельные предложения, было решено сделать для них отдельную таблицу.

\begin{center}
\begin{longtblr}[caption={Таблица предложений\label{tbl:sentence}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Код текста & Целое & Внешний ключ из таблицы тексты\\[0pt]
Предложение & Строка & \\[0pt]
Номер предложения & Целое & Порядковый номер предложения в тексте\\[0pt]
\end{longtblr}
\end{center}

Так как результат работы модели может отличать в зависимости от ее типа, то поле {}<<результат>>{} будет массивом.

\begin{center}
\begin{longtblr}[caption={Таблица результатов анализа текстов\label{tbl:text_result}}]{colspec={|X[l]|X[l]|X[l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Назначение}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Код предложения & Целое & Внешний ключ из таблицы предложения\\[0pt]
Код модели & Целое & Внешний ключ из таблицы модели\\[0pt]
Результат & Вещественный массив & Результат работы модели\\[0pt]
Обработано & Логическое & Показатель, обработано ли предложение или нет\\[0pt]
\end{longtblr}
\end{center}

Диаграмма полученной схемы базы данных рис. \ref{fig:database}.
\subsection{Проектирование базы данных для агрегации}
\label{sec:org9058574}
При сборе функциональных требований было выявлено, что надо быстро показывать количество собранных отзывов и индекс компаний.

Обработанные данные из таблицы~\ref{tbl:text_result} агрегируются для каждого квартала и рассчитываются по формуле \ref{eq:ethics}.
\begin{center}
\begin{longtblr}[caption={Таблица для расчета и показа индекса\label{tbl:index_calc}}]{colspec={|X[2,l]|X[1,l]|X[3,l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Год & Целое & Год за который был агрегирован индекс\\[0pt]
Квартал & Целое & Квартал за который был агрегирован индекс\\[0pt]
Название модели & Строка & \\[0pt]
Сайт источника & Строка & \\[0pt]
Тип источника & Строка & \\[0pt]
Название банка & Строка & \\[0pt]
Код банка & Целое & Для запросов через API\\[0pt]
Нейтральный & Целое & Количество нейтральных предложений за период\\[0pt]
Позитивный & Целое & Количество позитивных предложений за период\\[0pt]
Негативный & Целое & Количество негативных предложений за период\\[0pt]
Базовый индекс & Вещественное & Индекс для расчета итогового индекса\\[0pt]
Средний индекс & Вещественное & Индекс для расчета итогового индекса\\[0pt]
Std индекс & Вещественное & Индекс для расчета итогового индекса\\[0pt]
Индекс & Вещественное & Рассчитанный индекс\\[0pt]
\end{longtblr}
\end{center}

Собранные отзывы из таблицы~\ref{tbl:text} агрегируются для каждого месяца и рассчитывается количество собранных отзывов за месяц.
\begin{center}
\begin{longtblr}[caption={Таблица для расчета и показа индекса\label{tbl:index_calc}}]{colspec={|X[2,l]|X[1,l]|X[3,l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Дата & DateTime & \\[0pt]
Квартал & Целое & Квартал за который был агрегирован индекс\\[0pt]
Тип источника & Строка & \\[0pt]
Сайт & Строка & \\[0pt]
Количество отзывов & Целое & \\[0pt]
\end{longtblr}
\end{center}

Диаграмма полученной схемы базы данных рис. \ref{fig:database_views}.
\section{Проектирование модуля работы с данными}
\label{sec:org7d6e6d2}
Модуль будет представлять собой HTTP API для работой с базой данных.

При первом старте приложение будет получаться список компаний (банки, брокеры, микрокредитные организации и страховые) с сайта {}<<Центрального банка России>>{} и помещаться в базу данных. Из этих данных будет собираться лицензия компании и название компании, для микрокредитных организаций дополнительно будет собираться основной государственный регистрационный номер (ОГРН), так как под одной лицензией может работать несколько компаний. При последующих стартах приложение будет проверяться, что в каждом списке есть компании и новые компании не будут выгружаться.

Далее создаются объекты класса Bank с использованием полученных данных и добавляются в список cbr\textsubscript{banks}. Наконец, список cbr\textsubscript{banks} возвращается как результат работы функции.

Таким образом, принцип работы данного алгоритма заключается в извлечении необходимых данных из HTML-кода веб-страницы и преобразовании их в объекты класса Bank, что позволяет автоматизировать процесс получения и анализа информации о банках.

Для работы с источниками текстов необходимо сделать запросы для типов источников и самих источников. Также для обновления состояния сборщика данных надо сделать отдельный метод \texttt{PATCH}, который позволит обновлять время и состояние источника данных по идентификатору. Также при создании источника будет проверяться существует ли такой тип источника или нет. Если его не существует, то такой тип будет создаваться.

Сохранение текстов будет доступно по методу \texttt{POST} c передачей данных о тексте и состоянии сборщика данных. При выполнении запроса должно обновляться состояние сборщика данных, а каждый текст должен сохраняться, как набор предложений. При получении предложений должны выбираться такие предложения, которые еще не обработаны моделью.

Работа с моделями будет происходить аналогично источникам. При сохранении модели будет проверяться есть ли такой тип модели или нет. Если его нет, то он будет создан.

Также необходима возможность получения списка компаний с помощью API по различным сферам работы.

В результате проектирования должно получиться API, которое реализует запросы представленные в таблице  \ref{tbl:api_doc}.

\include{api_table}
\section{Проектирование модуля агрегации данных}
\label{sec:org41d5b02}
Для построения индекса этичности компаний будет ежедневно агрегироваться база данных и перестраиваться индексы.
\section{Проектирование модуля сбора данных}
\label{sec:org452c8ec}
У всех сборщиков данных одинаковый принцип работы (рис. \ref{fig:parser_flow}):
\begin{enumerate}
\item Сборщик данных запрашивает у модуля работы с базой данных список сохраненных компаний. Модуль отвечает на запрос, отправляя список сохраненных компаний обратно.
\item Сборщик данных запрашивает у сайта для сбора данных список компаний на сайте. Сайт отправляет список компаний обратно в сборщик данных.
\item После получения списка компаний, сборщик данных сохраняет только те компании, которые уже есть в основной базе данных. Это делается для того, чтобы связать компании которые представлены на сайте и в базе данных.
\item Затем, сборщик данных начинает собирать данные для каждой компании из списка. Это может быть сделано путем отправки запросов к API сайта или сканирования страниц сайта для поиска нужных данных. Собранные данные затем сохраняются в основной базе данных. Сбор данных будет происходить до тех пор пока не соберутся все отзывы для компании, или дата отзыва дойдет до даты предыдущего сбора данных.
\end{enumerate}

Каждый сборщик данных будет представлять класс, который реализует интерфейс с методом \texttt{parse}, который непосредственно запускает сбор данных. Также у каждого сборщика данных будет своя база данных для сохранения информации о компаниях.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/mermaid/parser_flow.png}
\caption{\label{fig:parser_flow}Схема работы сборщиков данных}
\end{figure}

\subsection{Проектирование сбора данных с banki.ru}
\label{sec:org5b8822f}
Для получения данных с сайта banki.ru будут отправляться запросы на их внутренний API. Для запросов надо иметь идентификатор компании с сайта, также надо иметь идентификатор компании из модуля работы с базой данных. Исходя из требований получилась база данных  \ref{tbl:banki_ru}. Диаграмма полученной схемы базы данных рис. \ref{fig:database_banki_ru}.

\begin{center}
\begin{longtblr}[caption={Таблица для сайта banki.ru\label{tbl:banki_ru}}]{colspec={|X[2,l]|X[1,l]|X[3,l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Идентификатор банка & Целое & Идентификатор банка в основной базе данных\\[0pt]
Имя банка & Строка & \\[0pt]
Код банка & Строка & Код банка для запросов по API\\[0pt]
\end{longtblr}
\end{center}

С этого сайта будут собираться данные о компаниях из пяти сфер:
\begin{enumerate}
\item \textbf{Отзывы на банки.}
Список банков будет получаться из \url{https://www.banki.ru/widget/ajax/bank\_list.json}. Затем они будут сравниваться по номеру лицензии с банками, которые есть в базе данных. Для получения отзывов о банках будут отправляться запросы на \url{https://www.banki.ru/services/responses/list/ajax/} и в параметры ссылки будет передаваться код банка и номер страницы с отзывами и из полученного json будут собираться данные об отзывах.
\item \textbf{Новости о банках.}
В качестве списка компаний будет использоваться такой же список, как и для банков. Для получения текста новостей сначала будет собираться список новостей для компании. Для этого будут отправляться запросы на \url{https://www.banki.ru/banks/bank/\{bank.bank\_code\}/news/} в зависимости от банка. Затем по каждой ссылке будет обрабатываться html код страницы и собираться текст новости.
\item \textbf{Отзывы на страховые компании.}
Список компаний будет получаться из \url{https://www.banki.ru/insurance/companies/}. Затем они будут сравниваться по номеру лицензии со страховыми, которые есть в базе данных. После этого будут собираться отзывы по \url{https://www.banki.ru/insurance/companies/}. Затем из каждой страницы компании для будет обрабатываться html код страницы и браться данные отзывов.
\item \textbf{Отзывы на брокеров.}
Для получения списка компаний данные будут браться из \url{https://www.banki.ru/investment/brokers/list/}. Затем они будут сравниваться по номеру лицензии с брокерами, которые есть в базе данных. После этого будут собираться отзывы по \url{https://www.banki.ru/investment/responses/company/broker/}. Затем из каждой страницы компании для будет обрабатываться html код страницы и браться данные отзывов.
\item \textbf{Отзывы на микрокредитные организации.}
Для получения списка компаний данные будут браться из \url{https://www.banki.ru/microloans/ajax/search}. Затем они будут сравниваться по номеру лицензии и ОГРН с компания, которые есть в базе данных. После этого будут собираться отзывы по \url{https://www.banki.ru/microloans/responses/ajax/responses/}. Затем из полученного json собираются отзывы о компании.
\end{enumerate}
В конце сбора данных для каждого типа компаний собранные отзывы будут отправляться в модуль работы с базой данных.
\subsection{Проектирование сбора данных с sravni.ru}
\label{sec:org7bfed30}
Для получения данных с сайта sravni.ru будут отправляться запросы на их внутренний API. Для запросов надо иметь идентификатор компании с сайта, также надо иметь идентификатор компании из модуля работы с базой данных, также для некоторых запросов надо иметь псевдоним компании (alias). Исходя из требований получилась база данных  \ref{tbl:sravni_ru}. Диаграмма полученной схемы базы данных рис. \ref{fig:database_sravni_ru}.

\begin{center}
\begin{longtblr}[caption={Таблица для сайта sravni.ru\label{tbl:sravni_ru}}]{colspec={|X[2,l]|X[1,l]|X[3,l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Идентификатор банка & Целое & Идентификатор банка в основной базе данных\\[0pt]
Код банка в sravni.ru & Целое & \\[0pt]
Старый код банка в sravni.ru & Целое & \\[0pt]
Псевдоним компании & Строка & \\[0pt]
Название банка & Строка & \\[0pt]
\end{longtblr}
\end{center}
Диаграмма полученной схемы базы данных рис. \ref{fig:database_sravni_ru}

С этого сайта будут собираться данные о компаниях из трех сфер:
\begin{enumerate}
\item \textbf{Отзывы на банки.}
Список банков будет получаться из \url{https://www.sravni.ru/proxy-organizations/organizations} с параметром \texttt{organizationType} равным \texttt{bank}. Затем они будут сравниваться по номеру лицензии с банками, которые есть в базе данных. Для получения отзывов о банках будут отправляться запросы на \url{https://www.sravni.ru/bank/\{bank\_info.alias\}/otzyvy/} и в параметры ссылки будет передаваться псевдоним банка и номер страницы с отзывами. И из полученного json будут собираться данные об отзывах.
\item \textbf{Отзывы на страховые компании.}
Список банков будет получаться из \url{https://www.sravni.ru/proxy-organizations/organizations} с параметром \texttt{organizationType} равным \texttt{insuranceCompany}. Затем они будут сравниваться по номеру лицензии со страховыми, которые есть в базе данных. Для получения отзывов о банках будут отправляться запросы на \url{https://www.sravni.ru/strakhovaja-kompanija/\{bank\_info.alias\}/otzyvy/} и в параметры ссылки будет передаваться псевдоним страховой и номер страницы с отзывами. И из полученного json будут собираться данные об отзывах.
\item \textbf{Отзывы на микрокредитные организации.}
Список банков будет получаться из \url{https://www.sravni.ru/proxy-organizations/organizations} с параметром \texttt{organizationType} равным \texttt{mfo}. Затем они будут сравниваться по номеру лицензии и ОГРН с компаниями, которые есть в базе данных. Для получения отзывов о банках будут отправляться запросы на \url{https://www.sravni.ru/zaimy/\{bank\_info.alias\}/otzyvy/} и в параметры ссылки будет передаваться псевдоним банка и номер страницы с отзывами. И из полученного json будут собираться данные об отзывах.
\end{enumerate}
В конце сбора данных для каждого типа компаний собранные отзывы будут отправляться в модуль работы с базой данных.
\subsection{Проектирование сбора данных с vk.com}
\label{sec:org8ea2891}
Для получения на сайт vk.com будут отправляться запросы на их API. Для этого предварительно будут собраны данные о всех организациях, которые у них представлены на сайте и перемещены в базу данных \ref{tbl:vk_com}. Диаграмма полученной схемы базы данных рис. \ref{fig:database_vk_com}.
\begin{center}
\begin{longtblr}[caption={Таблица для сайта vk.com\label{tbl:vk_com}}]{colspec={|X[2,l]|X[1,l]|X[3,l]|},rowhead = 1,hlines}
\textbf{Название} & \textbf{Тип} & \textbf{Описание}\\[0pt]
Идентификатор & Целое & Уникальный идентификатор\\[0pt]
Идентификатор на vk.com & Строка & \\[0pt]
Имя компании & Строка & \\[0pt]
Домен компании на vk.com & Строка & \\[0pt]
\end{longtblr}
\end{center}

Для доступа к API будет зарегистрировано приложение для получения ключа к нему. Для каждой компании будут выгружаться посты пока дата последней выгрузки не более чем дата последнего поста для этого будет отправляться запрос на \url{https://api.vk.com/method/wall.get}, куда будет подставляться токен приложения и идентификатор группы. Затем для каждого поста будут выгружаться комментарии по методу \url{https://api.vk.com/method/wall.getComments}, а затем отправляться в модуль работы с базой данных.
\section{Проектирование модуля обработки данных}
\label{sec:org796e3f0}
Модуль обработки данных будет представлять собой до обученную нейронную сеть Sentence-BERT. В качестве основы для обучения будет RuBERT \autocite{kuratov_adaptation_2019}. При использовании BERT для задачи классификации, добавляется небольшой слой нейронной сети в конце предобученной модели, который выполняет финальную классификацию. Этот слой называется {}<<головой классификации>>{} (classification head). Голова классификации содержит несколько слоев нейронной сети, которые принимают входные векторы, выходные значения которых интерпретируются как вероятности принадлежности к различным классам. Количество выходных нейронов в голове классификации равно количеству классов в вашей задаче. При дообучении BERT для задачи классификации, веса всех слоев в предобученной модели остаются неизменными, а только голова классификации обучается на задаче классификации с использованием обучающей выборки. Таким образом, голова классификации добавляется к BERT при задаче классификации, и обучается на конкретной задаче классификации, используя представления слов, полученные от предобученной модели BERT.

В этой работе для дообучения будет использоваться набор из 20,000 предложений, размеченный экспертами на соответствие этическим практикам.
\section{Выводы по главе}
\label{sec:orga825fef}
В данной главе были представлены результаты проектирования системы и ее отдельных компонентов, включая базы данных и API микросервисов для модуля анализа в универсальной рекомендательной системе.

Архитектура системы была определена с учетом функциональных требований и ограничений проекта. Каждый микросервис был разработан с учетом принципов микросервисной архитектуры и обеспечивает определенную функциональность, необходимую для реализации системы в целом.

Была спроектирована база данных для хранения информации об отзывах, источниках, моделях и компаниях. Базы данных были спроектированы с учетом требований к масштабируемости и производительности системы.

Также были спроектированы сервисы для работы с базой данных, ее агрегацией, сбором данных и обработки данных.

Таким образом, в данной главе были представлены результаты проектирования системы и ее компонентов, необходимых для реализации универсальной рекомендательной системы. Эти результаты будут использоваться при разработке и реализации системы в следующих этапах проекта.
\chapter{Реализация системы}
\label{sec:org2d8a0a3}
В данной главе описывается реализация системы.
\section{Реализация базы данных}
\label{sec:org4755bc5}
Для хранения информации в системе была выбрана СУБД PostgreSQL. Для создания базы данных был выбран подход {}<<code first>>{}, который позволяет определить структуру базы данных в виде классов на языке Python. Для этого использовалась библиотека Sqlalchemy \autocite{bayermichael_architecture_2012}, которая обеспечивает ORM-модель для работы с базами данных. При запуске приложения база данных будет создаваться автоматически на основе определенных классов.

Для определения структуры базы данных был создан базовый класс \texttt{DeclarativeBase}, который является родительским для всех классов, определяющих таблицы базы данных. Каждая таблица базы данных определяется в виде отдельного класса, который наследует базовый класс и содержит определения столбцов и связей между таблицами.

Для обеспечения возможности модернизации базы данных в дальнейшем была использована библиотека alembic, которая обеспечивает миграции базы данных и позволяет вносить изменения в структуру базы данных без потери данных.
\section{Реализация модуля работы с базой данных}
\label{sec:org9b9e443}
Для реализации API используется асинхронный фреймворк FastAPI и для взаимодействии с базой данных асинхронная библиотека asyncpg. Для валдиции приходящих данных и ответов для каждого запроса была создана своя модель с помощью библиотеки Pydantic.

При старте приложения сначала проверятся подключение с базой данных и проверяется ее версия, если она не актуальна, то выполняются миграции для ее актуализации. Затем проверятся список компаний, если список компаний пустой, то собирается данные о банках, брокера, страховых и микрофинансовых организациях.

Информация о банках будет собираться по ссылке \url{https://www.cbr.ru/banking\_sector/credit/FullCoList/}. Алгоритм начинается с получения объекта BeautifulSoup\autocite{richardsonleonard_beautiful_2007}, который содержит HTML-код веб-страницы. Затем происходит итерация по всем элементам таблицы, начиная со второй строки, так как в первой находится заголовки для каждой колонки. Для каждой строки таблицы находятся все ячейки, извлекаются регистрационный номер (номер лицензии) и название банка. В списке также есть платежные небанковские кредитные организации, которые имеют буквы на конце лицензии, например \texttt{3511-К} у {}<<Деньги.Мэйл.Ру>>{}. Для этого такие номера будут разделяться по {}<<->>{} и браться номер и преобразовываться в число. Затем собранные данные помещаются в базу данных.

Для сбора данных о брокерах будет обрабатываться excel файл, который доступен по ссылке \url{https://www.cbr.ru/vfs/finmarkets/files/supervision/list\_brokers.xlsx}, с помощью библиотеки pandas\autocite{team_pandas-devpandas_2023}. При запуске происходит загрузка таблицы с данными о брокерах в формате Excel, после чего данные из таблицы считываются. Затем происходит итерация по строкам таблицы и для каждой строки создается экземпляр класса Bank, который содержит информацию о банке-брокере, такую как номер лицензии, наименование организации и тип банка. Для удобства хранения номера лицензии, из них удалялись все знаки {}<<->>{}.

Для сбора данных о страховых будет обрабатываться excel файл, который доступен по ссылке \url{https://www.cbr.ru/vfs/finmarkets/files/supervision/list\_ssd.xlsx}. Так как в файле много строк, которые не содержат номеров или наименований банков, то они удаляются из него. Номера лицензий хранятся в формате \texttt{СИ № 3847} или \texttt{ОС № 1083 - 05} и для получения номера берется первое число которое встретилось в строке с помощью регулярного выражения. Затем полученная информация помещается в базе данных.

Для сбора данных о микрофинансовых организациях будет обрабатываться excel файл, который доступен по ссылке \url{https://www.cbr.ru/vfs/finmarkets/files/supervision/list\_ssd.xlsx}. В этом файле номер лицензии разбит по 5 ячейкам и в части из отсутствуют числа. Поэтому отсутствующие ячейки заполняются нулями и содержание ячеек объединяется для получения результата. Потом также берется название компании и эта информация помещается в базу данных.

API было реализовано согласно требованиям описанными во второй главе.

Алгоритм получения предложений для обработки проверяет, какие из них уже были обработаны моделью, а какие - нет. Если для каждого запроса искать пересечение множества предложений, которые еще не обработаны моделью и уже обработаны, это может занять много времени. Поэтому сначала выполняется запрос (\ref{lst:insert_unused}), который ищет предложения, еще не обработанные моделью. Если таких нет, то в таблицу с результатами добавляются 100 000 предложений с пустыми результатами, чтобы было проще искать предложения при дальнейших запросах. Затем с помощью запроса (\ref{lst:select_unused}) из таблицы с результатами выбираются предложения, еще не обработанные моделью.

\begin{lstlisting}[language=SQL,label=lst:insert_unused,caption={SQL запрос на вставку не обработанных предложений},captionpos=b,numbers=none]
INSERT INTO text_result (text_sentence_id, model_id, is_processed)
SELECT text_sentence.id, :model_id, false
FROM text_sentence
JOIN text ON text_result.text_id = text.id
JOIN source ON text.source_id = source.id
LEFT JOIN (
  SELECT text_result.text_sentence_id
  FROM text_result
  WHERE text_result.model_id = :model_id
) AS subq ON text_sentence.id = subq.text_sentence_id
WHERE source.site IN (:sources) AND subq.text_sentence_id IS NULL
LIMIT 100000;
\end{lstlisting}

\begin{lstlisting}[language=SQL,label=lst:select_unused,caption={SQL запрос на получение еще не обработанных предложений},captionpos=b,numbers=none]
SELECT text_sentence.id, text_sentence.sentence
FROM text_sentence
JOIN (
  SELECT text_result.text_sentence_id, text_result.id
  FROM text_result
  WHERE text_result.model_id = :model_id AND text_result.is_processed = false
  LIMIT :limit
) AS sub
ON text_sentence.id = sub.text_sentence_id;
\end{lstlisting}
\section{Реализация модуля агрегации данных}
\label{sec:orgc2f2309}
\section{Реализация модуля сбора данных}
\label{sec:orgf9e1284}
psycopg2
\section{Реализация модуля обработки текста}
\label{sec:org7154965}
\section{Развертывание системы}
\label{sec:org69905f0}
\section{Выводы по главе}
\label{sec:org458423f}
\chapter{Тестирование системы}
\label{sec:org99c2707}
наиписать также про линтеры и форматтеры
\chapter*{Заключение}
\label{sec:org9f8c817}
\putbibliography
\appendix
\include{tz}
\chapter{Схема базы данных}
\label{sec:orgcd72354}
\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/d2/database.png}
\caption{\label{fig:database}Схема базы данных}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/d2/views_database.png}
\caption{\label{fig:database_views}Схема базы данных для агрегаций}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/d2/banki_ru.png}
\caption{\label{fig:database_banki_ru}Схема базы данных сайта banki.ru}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/d2/sravni_ru.png}
\caption{\label{fig:database_sravni_ru}Схема базы данных сайта sravni.ru}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{img/d2/vk_com.png}
\caption{\label{fig:database_vk_com}Схема базы данных сайта vk.com}
\end{figure}
\end{document}
