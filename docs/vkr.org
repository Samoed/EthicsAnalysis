#+STARTUP: latexpreview
#+TITLE: Разработка сайта для автоматического сбора, анализа и визуализации информации по этичности компаний
#+AUTHOR: Соломатин Роман Игоревич
#+LANGUAGE: RU
#+LATEX_CLASS: HSEUniversity
#+LATEX_CLASS_OPTIONS: [PI, VKR]
#+bibliography: library.bib
#+cite_export: biblatex
#+OPTIONS: toc:nil H:4 ':t
#+LATEX_HEADER_EXTRA: \Abstract{В данной работе проведен анализ этичности разных компаний.
#+LATEX_HEADER_EXTRA:
#+LATEX_HEADER_EXTRA: В первой главе находится описание используемых алгоримов.
#+LATEX_HEADER_EXTRA:
#+LATEX_HEADER_EXTRA: Во второй главе представлено проектирование системы.
#+LATEX_HEADER_EXTRA:
#+LATEX_HEADER_EXTRA: В третьей главе представлена реализация системы.
#+LATEX_HEADER_EXTRA:
#+LATEX_HEADER_EXTRA: В четвертой главе представлено тестирование работы системы.
#+LATEX_HEADER_EXTRA:
#+LATEX_HEADER_EXTRA: Количество страниц - N, количество иллюстраций - N, количетсво таблиц - N.}

* Введение
:PROPERTIES:
:UNNUMBERED: t
:END:
При работе с различными компаниями возникают проблемы их надежности, то как они ведут себя в спорных ситуациях, есть ли сервисы направленные на взаимодействие с клиентами.

В настоящее время существуют сервисы, которые могут оценить этичность компании на основании судебных дел, но не на отзывах о компании.

Объект исследования – деятельность компаний.

Предмет исследования – программные средства для оценки этичности деятельности компаний.

Цель работы – создание системы для оценки этичности компаний.

Исходя из поставленной цели, необходимо:

1. Провести анализ предметной области
2. Провести анализ системы
3. Реализовать систему
4. Провести тестирование системы

Этап анализа должен:
1. Анализ предметной области
2. Анализ существующих алгоритмов

Этап проектирования должен включать:
1. Проектирование серверной части
2. Проектирование модели для определения этичности
3. Проектирование клиентской части приложения

Этап реализации должен включать:
1. Описание сбора данных
2. Реализации модели
3. Реализации серверной части
4. Реализации клиентской части

Этап тестирования должен включать:
1. Тестирование модели
2. Тестирование серверной части
3. Тестирование клиентской части
* Анализ предметной области
** Постановка задачи
В данный момент при выборе компаний приходится смотреть отзывы на различных сайтов и самому анализировать на сколько этична компания. Для этого будет реализована система, которая будет собирать отзывы с различных сайтов и анализировать их.
** BERT
BERT [cite:@devlin2018bert] (Bidirectional Encoder Representations from Transformers) -- это нейросетевая языковая модель, которая относится к классу трансформеров. Она состоит из 12 «базовых блоков» (слоев), а на каждом слое 768 параметров.

На вход модели подается предложение или пара предложений. Затем разделяется на отдельные слова (токены). Потом в начало последовательности токенов вставляется специальный токен =[CLS]=, обозначающий начало предложения или начало последовательности предложений. Пары предложений группируются в одну последовательность и разделяются с помощью специального токена =[SEP]=, затем к каждому токену добавляется эмбеддинг, показывающий к какому предложению относится токен. Потом все токены превращаются в эмбеддинги [[fig:inputemebeddings]] по механизму описаному в работе [cite:@NIPS2017_3f5ee243].

#+CAPTION: Пример ввода текста в модель
#+NAME: fig:inputemebeddings
#+ATTR_LATEX: :placement [h]
[[file:img/Input_Emebeddings.pdf]]

При обучении модель выполняет на 2 задания:
 1) Предсказание слова в предложении

    Поскольку стандартные языковые модели либо смотрят текст слева направо или справа налево [[fig:BERT_comparisons]], как ELMo[cite:@elmo] и GPT[cite:@radford2019language], они не подходят под некоторые типы заданий. Так как BERT двунаправленный, у каждого слова можно посмотреть его контекст, что позволит предсказать замаскированное слово.

    #+CAPTION: Сравнение принципов работы BERT, ELMo, GPT
    #+NAME: fig:BERT_comparisons
    #+ATTR_LATEX: :placement [h]
    [[file:img/BERT_comparisons.pdf]]

    Это задание обучается следующим образом -- 15% случайных слов заменяются в каждом предложении на специальный токен =[MASK]=, а затем предсказываются на основании контекста. Однако иногда слова заменяются не на специальны токена, в 10% заменяются на случайный токен и еще в 10% заменяются на случайное слово.

 2) Предсказание следующего предложения

    Для того чтобы обучить модель, которая понимает отношения предложений, она предсказывает, идут ли предложения друг за другом. Для этого с 50% вероятностью выбирают предложения, которые находятся рядом и наоборот. Пример ввода пары предложений в модель [[fig:bert_pretrainin]].

    #+CAPTION: Схемам работы BERT
    #+NAME: fig:bert_pretrainin
    #+ATTR_LATEX: :width 0.6\textwidth :placement [hbp]
    [[file:img/bert_pretrainin.png]]
** Sentense BERT
Sentense BERT [cite:@reimers-2019-sentence-bert] -- это модификация предобученных моделей BERT, которая использует 2 модели BERT, затем усреднят их выходы, а после с помощью функции ошибки выдаёт результат. Схема работы модели [[fig:sbert]] [[ref:fig:sbert]].
#+CAPTION: Схема работы SBERT
#+NAME: fig:sbert
#+ATTR_LATEX: :width 0.6\textwidth :placement [hbp]
[[file:img/sbert.png]]
Основное преимущество данной модели над классическим BERT: эмбеддинги предложений можно сравнивать друг с другом независимо и не пересчитывать их пару каждый раз. Например, если для поиска похожих предложений из 10000 для обычного BERT потребуется 50 миллионов вычислений различных пар предложений, и это займёт 50 часов, то Sentense BERT рассчитает эмбеддинг каждого предложения отдельно и потом их сравнит, и это займёт примерно 5 секунд.
* Проектирование системы
** Проектирование базы данных

** Проектирование архитектуры системы
*** Проектирование серверной части
*** Проектирование клиентской части

* Реализация системы
** Реализация серверной части
*** Реализация API
*** Реализация парсера banki.ru
*** Реализация парсера sravni.ru
*** Реализация модуля обработки текста
** Реализация клиентской части
* Тестирование системы
* Заключение
:PROPERTIES:
:UNNUMBERED: t
:END:
#+latex: \nocite{*}
#+LATEX: \putbibliography
#+LATEX: \appendix
